# LINE_FOLLOWING_ROBOT



# My Line Following Robot Project

## Project Overview

Welcome to my personal project focused on robotic programming using CoppeliaSim and Jupyter Notebook. This series of workshops features various line-following robots, each designed to tackle increasingly complex challenges. This journey has not only been a learning experience but also a fun exploration of robotics and programming!

## Workshop Details

1. **Line Following Robot**
   - In this first workshop, I built a basic line-following robot equipped with three sensors: middle, left, and right.
   - The robot uses infrared sensors to detect the line on the ground and employs simple control logic to follow it smoothly. 
   - I implemented a basic PID controller to enhance the robot's responsiveness and precision in following the line.

2. **Maze-Solving Robot**
   - For the second workshop, I adapted the line-following robot to solve a maze. 
   - Utilizing the same three sensors, the robot now must make decisions to navigate through twists and turns.
   - I developed algorithms that allow the robot to detect intersections and adjust its path to find the exit, showcasing its adaptability.

3. **Walled Maze Robot**
   - This workshop introduced a new robot featuring five sensors: a front camera, front, left, front right, back left, and back right.
   - The goal was to escape from a walled maze using the robot's comprehensive sensor array.
   - I implemented advanced algorithms that enable the robot to detect walls and navigate obstacles effectively.

4. **Behavior Tree Maze Solver**
   - In the fourth workshop, I incorporated a behavior tree for decision-making in the walled maze.
   - This approach allows for more complex behaviors and strategies, enabling the robot to adapt its actions based on environmental feedback.
   - The behavior tree structure made it easier to manage various tasks, improving the overall efficiency of maze navigation.

5. **Image-Based Maze Navigation**
   - In the final workshop, I tackled a maze that features images along the walls.
   - The robot uses its front camera to recognize these images and make decisions on where to turn based on what it sees.
   - Additionally, the robot has the capability to take pictures during its navigation, adding a new layer of interaction with the environment.

## Tech Stack

- **CoppeliaSim**: A powerful simulation platform for robotics, used to model and test my robots.
- **Jupyter Notebook**: An interactive environment where I write, test, and visualize my code.
- **Python**: The programming language of choice for developing algorithms and controlling the robots.

## Getting Started

To replicate my project and run the simulations, follow these steps:

1. **Install CoppeliaSim**: Download it from their official website: https://www.coppeliarobotics.com/
2. **Set Up Jupyter Notebook**: You can install Jupyter via Anaconda or pip. Make sure you have it running on your system.
3. **Clone the Repository**: Copy this repository to your local machine using:

4. **Run the Simulations**: Open the relevant Jupyter Notebooks for each workshop. Execute the cells to see the robots in action!

## Final Thoughts

This project has been an incredible journey into the world of robotics. Each workshop has contributed to my understanding of programming, sensor integration, and decision-making algorithms. Iâ€™ve enjoyed every moment, from overcoming challenges to watching the robots navigate their environments.

If you have any questions, suggestions, or would like to collaborate, feel free to reach out! Happy exploring!
